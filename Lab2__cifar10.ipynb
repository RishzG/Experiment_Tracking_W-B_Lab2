{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "255fb0bf",
      "metadata": {
        "id": "255fb0bf"
      },
      "outputs": [],
      "source": [
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b86dbf79",
      "metadata": {
        "id": "b86dbf79"
      },
      "outputs": [],
      "source": [
        "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"\n",
        "os.environ[\"TF_FORCE_GPU_ALLOW_GROWTH\"] = \"true\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "077b4eef",
      "metadata": {
        "id": "077b4eef"
      },
      "outputs": [],
      "source": [
        "\n",
        "import wandb\n",
        "import numpy as np\n",
        "import time\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as k\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.applications.mobilenet_v2 import (\n",
        "    preprocess_input,\n",
        "    MobileNetV2\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Configure GPU memory growth to prevent OOM\n",
        "gpus = tf.config.list_physical_devices('GPU')\n",
        "if gpus:\n",
        "    try:\n",
        "        for gpu in gpus:\n",
        "            tf.config.experimental.set_memory_growth(gpu, True)\n",
        "    except RuntimeError as e:\n",
        "        print(f\"Memory growth setting error: {e}\")\n",
        "\n",
        "# Enable mixed precision for better T4 performance\n",
        "tf.keras.mixed_precision.set_global_policy('mixed_float16')"
      ],
      "metadata": {
        "id": "9IBQzja97V4G"
      },
      "id": "9IBQzja97V4G",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "aaef52de",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aaef52de",
        "outputId": "5e6db999-7056-47ac-850f-943d4ddcfc7a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mrishg\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "wandb.login()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "4fd8496f",
      "metadata": {
        "id": "4fd8496f"
      },
      "outputs": [],
      "source": [
        "class LogLRCallback(k.callbacks.Callback):\n",
        "    \"\"\"Logs optimizer learning rate after each epoch.\"\"\"\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        opt = self.model.optimizer\n",
        "        lr = opt.learning_rate\n",
        "        lr_val = float(lr.numpy() if hasattr(lr, \"numpy\") else lr)\n",
        "        wandb.log({\"lr\": lr_val})\n",
        "\n",
        "class LogSamplesCallback(k.callbacks.Callback):\n",
        "    \"\"\"Logs sample predictions after each epoch.\"\"\"\n",
        "    def __init__(self, x_test, y_test, labels):\n",
        "        self.x = x_test[:16]\n",
        "        self.y = y_test[:16]\n",
        "        self.labels = labels\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        preds = self.model.predict(self.x, verbose=0)\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        true  = np.argmax(self.y, axis=1)\n",
        "\n",
        "        images = []\n",
        "        for i in range(len(self.x)):\n",
        "            images.append(\n",
        "                wandb.Image(\n",
        "                    self.x[i].astype(np.uint8),\n",
        "                    caption=f\"Pred: {self.labels[preds[i]]}, True: {self.labels[true[i]]}\"\n",
        "                )\n",
        "            )\n",
        "        wandb.log({\"sample_predictions\": images})\n",
        "\n",
        "\n",
        "class ConfusionMatrixCallback(k.callbacks.Callback):\n",
        "    \"\"\"Logs confusion matrix each epoch.\"\"\"\n",
        "    def __init__(self, x_test, y_test, labels):\n",
        "        self.x = x_test\n",
        "        self.y = y_test\n",
        "        self.labels = labels\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        preds = self.model.predict(self.x, verbose=0)\n",
        "        preds = np.argmax(preds, axis=1)\n",
        "        true  = np.argmax(self.y, axis=1)\n",
        "\n",
        "        wandb.log({\n",
        "            \"confusion_matrix\": wandb.plot.confusion_matrix(\n",
        "                y_true=true,\n",
        "                preds=preds,\n",
        "                class_names=self.labels\n",
        "            )\n",
        "        })\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --------------------- NEW CALLBACK ---------------------------\n",
        "class EpochTimeCallback(k.callbacks.Callback):\n",
        "    \"\"\"Logs how long each epoch takes.\"\"\"\n",
        "    def on_epoch_begin(self, epoch, logs=None):\n",
        "        self.start_time = time.time()\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs=None):\n",
        "        epoch_time = time.time() - self.start_time\n",
        "        wandb.log({\"epoch_time_sec\": epoch_time})\n",
        "\n"
      ],
      "metadata": {
        "id": "FwOM8KAMtLmx"
      },
      "id": "FwOM8KAMtLmx",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CIFAR10Trainer:\n",
        "\n",
        "    def __init__(self):\n",
        "\n",
        "        self.labels = [\n",
        "            \"airplane\",\"automobile\",\"bird\",\"cat\",\"deer\",\n",
        "            \"dog\",\"frog\",\"horse\",\"ship\",\"truck\"\n",
        "        ]\n",
        "        self.num_classes = 10\n",
        "\n",
        "        self.config = {\n",
        "            \"dropout\": 0.25,\n",
        "            \"learn_rate\": 0.0005,\n",
        "            \"epochs\": 5,\n",
        "            \"batch_size\": 32,   # smaller batch to avoid GPU OOM\n",
        "            \"base_trainable\": False\n",
        "        }\n",
        "\n",
        "        self.run = wandb.init(\n",
        "            project=\"CIFAR10-MobileNetV2\",\n",
        "            config=self.config,\n",
        "            name=\"cifar10_transfer_learning_run\"\n",
        "        )\n",
        "\n",
        "        self._prepare_data()\n",
        "\n",
        "\n",
        "    # ===========================================================\n",
        "    # DATA PIPELINE (memory safe)\n",
        "    # ===========================================================\n",
        "    def _prepare_data(self):\n",
        "\n",
        "        (xtr, ytr), (xte, yte) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "        AUTOTUNE = tf.data.AUTOTUNE\n",
        "\n",
        "        xtr = tf.cast(xtr, tf.float32)\n",
        "        xte = tf.cast(xte, tf.float32)\n",
        "\n",
        "        target_size = (160, 160)\n",
        "\n",
        "        def preprocess(image, label):\n",
        "            # image: (32,32,3), label: shape (1,)\n",
        "            image = tf.image.resize(image, target_size)\n",
        "            image = preprocess_input(image)\n",
        "\n",
        "            # Fix label shape: (1,) -> ()\n",
        "            label = tf.squeeze(label, axis=0)\n",
        "            label = tf.one_hot(label, depth=self.num_classes)  # shape (10,)\n",
        "\n",
        "            return image, label\n",
        "\n",
        "        # TRAIN DS\n",
        "        train_ds = tf.data.Dataset.from_tensor_slices((xtr, ytr))\n",
        "        train_ds = train_ds.shuffle(50000)\n",
        "        train_ds = train_ds.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "        train_ds = train_ds.batch(self.config[\"batch_size\"])\n",
        "        train_ds = train_ds.prefetch(AUTOTUNE)\n",
        "\n",
        "        # TEST DS\n",
        "        test_ds = tf.data.Dataset.from_tensor_slices((xte, yte))\n",
        "        test_ds = test_ds.map(preprocess, num_parallel_calls=AUTOTUNE)\n",
        "        test_ds = test_ds.batch(self.config[\"batch_size\"])\n",
        "        test_ds = test_ds.prefetch(AUTOTUNE)\n",
        "\n",
        "        self.train_ds = train_ds\n",
        "        self.test_ds = test_ds\n",
        "\n",
        "        # Extract 1 small numpy batch for callbacks (sample + confusion matrix)\n",
        "        for xb, yb in test_ds.take(1):\n",
        "            self.sample_x_test = xb.numpy()\n",
        "            self.sample_y_test = yb.numpy()\n",
        "\n",
        "\n",
        "    # ===========================================================\n",
        "    # MODEL: MobileNetV2 (transfer learning)\n",
        "    # ===========================================================\n",
        "    def _build_model(self):\n",
        "\n",
        "        base = MobileNetV2(\n",
        "            include_top=False,\n",
        "            weights=\"imagenet\",\n",
        "            pooling=\"avg\",\n",
        "            input_shape=(160, 160, 3)\n",
        "        )\n",
        "\n",
        "        base.trainable = self.config[\"base_trainable\"]\n",
        "\n",
        "        x = k.layers.Dropout(self.config[\"dropout\"])(base.output)\n",
        "        output = k.layers.Dense(self.num_classes, activation=\"softmax\")(x)\n",
        "\n",
        "        model = k.Model(inputs=base.input, outputs=output)\n",
        "\n",
        "        opt = k.optimizers.Adam(self.config[\"learn_rate\"])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer=opt,\n",
        "            loss=\"categorical_crossentropy\",\n",
        "            metrics=[\"accuracy\"]\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "    # ===========================================================\n",
        "    # TRAIN\n",
        "    # ===========================================================\n",
        "    def train(self):\n",
        "\n",
        "        model = self._build_model()\n",
        "\n",
        "        callbacks = [\n",
        "            LogLRCallback(),\n",
        "            LogSamplesCallback(self.sample_x_test, self.sample_y_test, self.labels),\n",
        "            ConfusionMatrixCallback(self.sample_x_test, self.sample_y_test, self.labels),\n",
        "            EpochTimeCallback()\n",
        "            # NOTE: We intentionally removed wandb.keras.WandbCallback\n",
        "        ]\n",
        "\n",
        "        model.fit(\n",
        "            self.train_ds,\n",
        "            epochs=self.config[\"epochs\"],\n",
        "            validation_data=self.test_ds,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # Final evaluation\n",
        "        loss, acc = model.evaluate(self.test_ds, verbose=0)\n",
        "        wandb.log({\"final/loss\": loss, \"final/accuracy\": acc})\n",
        "\n",
        "        self._log_model_artifact(model)\n",
        "        self.run.finish()\n",
        "\n",
        "\n",
        "    # ===========================================================\n",
        "    # MODEL ARTIFACT SAVE\n",
        "    # ===========================================================\n",
        "    def _log_model_artifact(self, model):\n",
        "        model.save(\"mobilenetv2_cifar10.h5\")\n",
        "        artifact = wandb.Artifact(\"mobilenetv2_cifar10\", type=\"model\")\n",
        "        artifact.add_file(\"mobilenetv2_cifar10.h5\")\n",
        "        self.run.log_artifact(artifact)\n"
      ],
      "metadata": {
        "id": "lidMnlKjtNiV"
      },
      "id": "lidMnlKjtNiV",
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# RUN TRAINING\n",
        "# ============================================================\n",
        "\n",
        "CIFAR10Trainer().train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 831
        },
        "id": "Z8St3bo927ro",
        "outputId": "0914dd47-d331-4b4b-df97-e1bcf29556ef"
      },
      "id": "Z8St3bo927ro",
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Finishing previous runs because reinit is set to 'default'."
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cifar10_transfer_learning_run</strong> at: <a href='https://wandb.ai/rishg/CIFAR10-MobileNetV2/runs/tifzc45b' target=\"_blank\">https://wandb.ai/rishg/CIFAR10-MobileNetV2/runs/tifzc45b</a><br> View project at: <a href='https://wandb.ai/rishg/CIFAR10-MobileNetV2' target=\"_blank\">https://wandb.ai/rishg/CIFAR10-MobileNetV2</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251117_223152-tifzc45b/logs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.22.3"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20251117_223347-whxds3ou</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/rishg/CIFAR10-MobileNetV2/runs/whxds3ou' target=\"_blank\">cifar10_transfer_learning_run</a></strong> to <a href='https://wandb.ai/rishg/CIFAR10-MobileNetV2' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/rishg/CIFAR10-MobileNetV2' target=\"_blank\">https://wandb.ai/rishg/CIFAR10-MobileNetV2</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/rishg/CIFAR10-MobileNetV2/runs/whxds3ou' target=\"_blank\">https://wandb.ai/rishg/CIFAR10-MobileNetV2/runs/whxds3ou</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m110s\u001b[0m 59ms/step - accuracy: 0.6747 - loss: 0.9837 - val_accuracy: 0.8490 - val_loss: 0.4436\n",
            "Epoch 2/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8391 - loss: 0.4644 - val_accuracy: 0.8572 - val_loss: 0.4103\n",
            "Epoch 3/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8500 - loss: 0.4326 - val_accuracy: 0.8641 - val_loss: 0.4028\n",
            "Epoch 4/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8546 - loss: 0.4141 - val_accuracy: 0.8595 - val_loss: 0.4221\n",
            "Epoch 5/5\n",
            "\u001b[1m1563/1563\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 12ms/step - accuracy: 0.8635 - loss: 0.3956 - val_accuracy: 0.8686 - val_loss: 0.3909\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch_time_sec</td><td>█▁▁▁▁</td></tr><tr><td>final/accuracy</td><td>▁</td></tr><tr><td>final/loss</td><td>▁</td></tr><tr><td>lr</td><td>▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch_time_sec</td><td>18.84802</td></tr><tr><td>final/accuracy</td><td>0.8686</td></tr><tr><td>final/loss</td><td>0.3909</td></tr><tr><td>lr</td><td>0.0005</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cifar10_transfer_learning_run</strong> at: <a href='https://wandb.ai/rishg/CIFAR10-MobileNetV2/runs/whxds3ou' target=\"_blank\">https://wandb.ai/rishg/CIFAR10-MobileNetV2/runs/whxds3ou</a><br> View project at: <a href='https://wandb.ai/rishg/CIFAR10-MobileNetV2' target=\"_blank\">https://wandb.ai/rishg/CIFAR10-MobileNetV2</a><br>Synced 5 W&B file(s), 55 media file(s), 8 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20251117_223347-whxds3ou/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8MnaWdQV3GY7"
      },
      "id": "8MnaWdQV3GY7",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}